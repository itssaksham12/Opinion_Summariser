{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (1.34.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (1.24.4)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (2.32.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: toolz in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (6.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair<6,>=4.0->streamlit) (3.17.0)\n",
      "Requirement already satisfied: pandas in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: wordcloud in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from wordcloud) (1.24.4)\n",
      "Requirement already satisfied: pillow in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from wordcloud) (10.3.0)\n",
      "Requirement already satisfied: matplotlib in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from wordcloud) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib->wordcloud) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: nltk in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from nltk) (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit \n",
    "!pip install pandas\n",
    "!pip install wordcloud \n",
    "!pip install nltk\n",
    "import streamlit as st \n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from heapq import nlargest\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"/Users/sakshamfaujdar/minor project 2/articles1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cufflinks\n",
      "  Using cached cufflinks-0.17.3.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from cufflinks) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from cufflinks) (2.0.3)\n",
      "Collecting plotly>=4.1.1 (from cufflinks)\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from cufflinks) (1.16.0)\n",
      "Collecting colorlover>=0.2.1 (from cufflinks)\n",
      "  Using cached colorlover-0.3.0-py3-none-any.whl.metadata (421 bytes)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from cufflinks) (69.5.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from cufflinks) (8.12.2)\n",
      "Collecting ipywidgets>=7.0.0 (from cufflinks)\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: backcall in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (4.9.0)\n",
      "Requirement already satisfied: appnope in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from ipywidgets>=7.0.0->cufflinks) (0.2.2)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets>=7.0.0->cufflinks)\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets>=7.0.0->cufflinks)\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas>=0.19.2->cufflinks) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas>=0.19.2->cufflinks) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas>=0.19.2->cufflinks) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly>=4.1.1->cufflinks) (8.3.0)\n",
      "Requirement already satisfied: packaging in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly>=4.1.1->cufflinks) (24.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.3.0->cufflinks) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pexpect>4.3->ipython>=5.3.0->cufflinks) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.3.0->cufflinks) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from stack-data->ipython>=5.3.0->cufflinks) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from stack-data->ipython>=5.3.0->cufflinks) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from stack-data->ipython>=5.3.0->cufflinks) (0.2.2)\n",
      "Using cached colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m552.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: cufflinks\n",
      "  Building wheel for cufflinks (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cufflinks: filename=cufflinks-0.17.3-py3-none-any.whl size=67899 sha256=0d282ba15fbecb252088fbb45194d9a292236e113cd29a98bef9e99bd0e032f2\n",
      "  Stored in directory: /Users/sakshamfaujdar/Library/Caches/pip/wheels/6b/76/62/6da97734911ffcbdd559fd1a3f28526321f0ae699182a23866\n",
      "Successfully built cufflinks\n",
      "Installing collected packages: colorlover, widgetsnbextension, plotly, jupyterlab-widgets, ipywidgets, cufflinks\n",
      "Successfully installed colorlover-0.3.0 cufflinks-0.17.3 ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 plotly-5.22.0 widgetsnbextension-4.0.10\n",
      "Collecting plotly_express\n",
      "  Using cached plotly_express-0.4.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly_express) (2.0.3)\n",
      "Requirement already satisfied: plotly>=4.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly_express) (5.22.0)\n",
      "Collecting statsmodels>=0.9.0 (from plotly_express)\n",
      "  Downloading statsmodels-0.14.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting scipy>=0.18 (from plotly_express)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m675.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m569.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting patsy>=0.5 (from plotly_express)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly_express) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas>=0.20.0->plotly_express) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas>=0.20.0->plotly_express) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas>=0.20.0->plotly_express) (2024.1)\n",
      "Requirement already satisfied: six in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from patsy>=0.5->plotly_express) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly>=4.1.0->plotly_express) (8.3.0)\n",
      "Requirement already satisfied: packaging in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from plotly>=4.1.0->plotly_express) (24.0)\n",
      "Using cached plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.1-cp38-cp38-macosx_11_0_arm64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: scipy, patsy, statsmodels, plotly_express\n",
      "Successfully installed patsy-0.5.6 plotly_express-0.4.1 scipy-1.10.1 statsmodels-0.14.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install cufflinks\n",
    "!pip install plotly_express\n",
    "import plotly_express as pe\n",
    "import cufflinks as cf\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.dropna of        Unnamed: 0     id                                              title  \\\n",
       "0               0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1               1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2               2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3               3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4               4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "...           ...    ...                                                ...   \n",
       "49995       53287  73465   Rex Tillerson Says Climate Change Is Real, but …   \n",
       "49996       53288  73466  The Biggest Intelligence Questions Raised by t...   \n",
       "49997       53289  73467  Trump Announces Plan That Does Little to Resol...   \n",
       "49998       53290  73468    Dozens of For-Profit Colleges Could Soon Close    \n",
       "49999       53291  73469                       The Milky Way’s Stolen Stars   \n",
       "\n",
       "          publication                         author        date    year  \\\n",
       "0      New York Times                     Carl Hulse  2016-12-31  2016.0   \n",
       "1      New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0   \n",
       "2      New York Times                   Margalit Fox  2017-01-06  2017.0   \n",
       "3      New York Times               William McDonald  2017-04-10  2017.0   \n",
       "4      New York Times                  Choe Sang-Hun  2017-01-02  2017.0   \n",
       "...               ...                            ...         ...     ...   \n",
       "49995        Atlantic                 Robinson Meyer  2017-01-11  2017.0   \n",
       "49996        Atlantic                     Amy Zegart  2017-01-11  2017.0   \n",
       "49997        Atlantic                  Jeremy Venook  2017-01-11  2017.0   \n",
       "49998        Atlantic                    Emily DeRuy  2017-01-11  2017.0   \n",
       "49999        Atlantic                   Marina Koren  2017-01-11  2017.0   \n",
       "\n",
       "       month  url                                            content  \n",
       "0       12.0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
       "1        6.0  NaN  After the bullet shells get counted, the blood...  \n",
       "2        1.0  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3        4.0  NaN  Death may be the great equalizer, but it isn’t...  \n",
       "4        1.0  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  \n",
       "...      ...  ...                                                ...  \n",
       "49995    1.0  NaN  As chairman and CEO of ExxonMobil, Rex Tillers...  \n",
       "49996    1.0  NaN  I’ve spent nearly 20 years looking at intellig...  \n",
       "49997    1.0  NaN    Donald Trump will not be taking necessary st...  \n",
       "49998    1.0  NaN  Dozens of   colleges could be forced to close ...  \n",
       "49999    1.0  NaN  The force of gravity can be described using a ...  \n",
       "\n",
       "[50000 rows x 10 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'title', 'publication', 'author', 'date', 'year',\n",
       "       'month', 'url', 'content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                            content  \n",
       "0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  NaN  After the bullet shells get counted, the blood...  \n",
       "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  NaN  Death may be the great equalizer, but it isn’t...  \n",
       "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>53287</td>\n",
       "      <td>73465</td>\n",
       "      <td>Rex Tillerson Says Climate Change Is Real, but …</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Robinson Meyer</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As chairman and CEO of ExxonMobil, Rex Tillers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>53288</td>\n",
       "      <td>73466</td>\n",
       "      <td>The Biggest Intelligence Questions Raised by t...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Amy Zegart</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I’ve spent nearly 20 years looking at intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>53289</td>\n",
       "      <td>73467</td>\n",
       "      <td>Trump Announces Plan That Does Little to Resol...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Jeremy Venook</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Trump will not be taking necessary st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>53290</td>\n",
       "      <td>73468</td>\n",
       "      <td>Dozens of For-Profit Colleges Could Soon Close</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Emily DeRuy</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dozens of   colleges could be forced to close ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>53291</td>\n",
       "      <td>73469</td>\n",
       "      <td>The Milky Way’s Stolen Stars</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Marina Koren</td>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The force of gravity can be described using a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              title  \\\n",
       "49995       53287  73465   Rex Tillerson Says Climate Change Is Real, but …   \n",
       "49996       53288  73466  The Biggest Intelligence Questions Raised by t...   \n",
       "49997       53289  73467  Trump Announces Plan That Does Little to Resol...   \n",
       "49998       53290  73468    Dozens of For-Profit Colleges Could Soon Close    \n",
       "49999       53291  73469                       The Milky Way’s Stolen Stars   \n",
       "\n",
       "      publication          author        date    year  month  url  \\\n",
       "49995    Atlantic  Robinson Meyer  2017-01-11  2017.0    1.0  NaN   \n",
       "49996    Atlantic      Amy Zegart  2017-01-11  2017.0    1.0  NaN   \n",
       "49997    Atlantic   Jeremy Venook  2017-01-11  2017.0    1.0  NaN   \n",
       "49998    Atlantic     Emily DeRuy  2017-01-11  2017.0    1.0  NaN   \n",
       "49999    Atlantic    Marina Koren  2017-01-11  2017.0    1.0  NaN   \n",
       "\n",
       "                                                 content  \n",
       "49995  As chairman and CEO of ExxonMobil, Rex Tillers...  \n",
       "49996  I’ve spent nearly 20 years looking at intellig...  \n",
       "49997    Donald Trump will not be taking necessary st...  \n",
       "49998  Dozens of   colleges could be forced to close ...  \n",
       "49999  The force of gravity can be described using a ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: networkx\n",
      "Successfully installed networkx-3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sakshamfaujdar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sakshamfaujdar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sakshamfaujdar/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sakshamfaujdar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(text):        \n",
    "    sentences =[]        \n",
    "    sentences = sent_tokenize(text)    \n",
    "    for sentence in sentences:        \n",
    "        sentence.replace(\"[^a-zA-Z0-9]\",\" \")     \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(content):\n",
    "    global article_sent\n",
    "    content = content.str.lower()  \n",
    "    content = content.apply(lambda x: cleanhtml(x))\n",
    "    content = content.apply(lambda x: re.sub('\\S+@\\S+','', x))\n",
    "    content = content.apply(lambda x: re.sub(\"((http\\://|https\\://|ftp\\://)|(www.))+(([a-zA-Z0-9\\.-]+\\.[a-zA-Z]{2,4})|([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(/[a-zA-Z0-9%:/-_\\?\\.'~]*)?\",'', x))\n",
    "    content = content.apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
    "    content = content.apply(lambda x: expand_contractions(x))\n",
    "    content = content.apply(lambda x: x.replace(\"'s\", ''))\n",
    "    content = content.apply(lambda x: x.replace('’s', ''))\n",
    "    content = content.apply(lambda x: x.replace(\"\\'s\", ''))\n",
    "    content = content.apply(lambda x: x.replace(\"\\’s\", ''))\n",
    "    content = content.apply(lambda x: re.sub(' +', ' ',x))\n",
    "    content = content.apply(lambda x: ''.join(word for word in x if word not in punctuation))\n",
    "    content = content.apply(lambda x: re.sub(' +', ' ',x))\n",
    "    content = content.apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n",
    "    article_sent = content.copy() \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"doesn’t\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"don’t\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y’all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "\"ain’t\": \"am not\",\n",
    "\"aren’t\": \"are not\",\n",
    "\"can’t\": \"cannot\",\n",
    "\"can’t’ve\": \"cannot have\",\n",
    "\"’cause\": \"because\",\n",
    "\"could’ve\": \"could have\",\n",
    "\"couldn’t\": \"could not\",\n",
    "\"couldn’t’ve\": \"could not have\",\n",
    "\"didn’t\": \"did not\",\n",
    "\"doesn’t\": \"does not\",\n",
    "\"don’t\": \"do not\",\n",
    "\"don’t\": \"do not\",\n",
    "\"hadn’t\": \"had not\",\n",
    "\"hadn’t’ve\": \"had not have\",\n",
    "\"hasn’t\": \"has not\",\n",
    "\"haven’t\": \"have not\",\n",
    "\"he’d\": \"he had\",\n",
    "\"he’d’ve\": \"he would have\",\n",
    "\"he’ll\": \"he will\",\n",
    "\"he’ll’ve\": \"he will have\",\n",
    "\"he’s\": \"he is\",\n",
    "\"how’d\": \"how did\",\n",
    "\"how’d’y\": \"how do you\",\n",
    "\"how’ll\": \"how will\",\n",
    "\"how’s\": \"how is\",\n",
    "\"i’d\": \"i would\",\n",
    "\"i’d’ve\": \"i would have\",\n",
    "\"i’ll\": \"i will\",\n",
    "\"i’ll’ve\": \"i will have\",\n",
    "\"i’m\": \"i am\",\n",
    "\"i’ve\": \"i have\",\n",
    "\"isn’t\": \"is not\",\n",
    "\"it’d\": \"it would\",\n",
    "\"it’d’ve\": \"it would have\",\n",
    "\"it’ll\": \"it will\",\n",
    "\"it’ll’ve\": \"it will have\",\n",
    "\"it’s\": \"it is\",\n",
    "\"let’s\": \"let us\",\n",
    "\"ma’am\": \"madam\",\n",
    "\"mayn’t\": \"may not\",\n",
    "\"might’ve\": \"might have\",\n",
    "\"mightn’t\": \"might not\",\n",
    "\"mightn’t’ve\": \"might not have\",\n",
    "\"must’ve\": \"must have\",\n",
    "\"mustn’t\": \"must not\",\n",
    "\"mustn’t’ve\": \"must not have\",\n",
    "\"needn’t\": \"need not\",\n",
    "\"needn’t’ve\": \"need not have\",\n",
    "\"o’clock\": \"of the clock\",\n",
    "\"oughtn’t\": \"ought not\",\n",
    "\"oughtn’t’ve\": \"ought not have\",\n",
    "\"shan’t\": \"shall not\",\n",
    "\"sha’n’t\": \"shall not\",\n",
    "\"shan’t’ve\": \"shall not have\",\n",
    "\"she’d\": \"she would\",\n",
    "\"she’d’ve\": \"she would have\",\n",
    "\"she’ll\": \"she will\",\n",
    "\"she’ll’ve\": \"she will have\",\n",
    "\"she’s\": \"she is\",\n",
    "\"should’ve\": \"should have\",\n",
    "\"shouldn’t\": \"should not\",\n",
    "\"shouldn’t’ve\": \"should not have\",\n",
    "\"so’ve\": \"so have\",\n",
    "\"so’s\": \"so is\",\n",
    "\"that’d\": \"that would\",\n",
    "\"that’d’ve\": \"that would have\",\n",
    "\"that’s\": \"that is\",\n",
    "\"there’d\": \"there would\",\n",
    "\"there’d’ve\": \"there would have\",\n",
    "\"there’s\": \"there is\",\n",
    "\"they’d\": \"they would\",\n",
    "\"they’d’ve\": \"they would have\",\n",
    "\"they’ll\": \"they will\",\n",
    "\"they’ll’ve\": \"they will have\",\n",
    "\"they’re\": \"they are\",\n",
    "\"they’ve\": \"they have\",\n",
    "\"to’ve\": \"to have\",\n",
    "\"wasn’t\": \"was not\",\n",
    "\"we’d\": \"we would\",\n",
    "\"we’d’ve\": \"we would have\",\n",
    "\"we’ll\": \"we will\",\n",
    "\"we’ll’ve\": \"we will have\",\n",
    "\"we’re\": \"we are\",\n",
    "\"we’ve\": \"we have\",\n",
    "\"weren’t\": \"were not\",\n",
    "\"what’ll\": \"what will\",\n",
    "\"what’ll’ve\": \"what will have\",\n",
    "\"what’re\": \"what are\",\n",
    "\"what’s\": \"what is\",\n",
    "\"what’ve\": \"what have\",\n",
    "\"when’s\": \"when is\",\n",
    "\"when’ve\": \"when have\",\n",
    "\"where’d\": \"where did\",\n",
    "\"where’s\": \"where is\",\n",
    "\"where’ve\": \"where have\",\n",
    "\"who’ll\": \"who will\",\n",
    "\"who’ll’ve\": \"who will have\",\n",
    "\"who’s\": \"who is\",\n",
    "\"who’ve\": \"who have\",\n",
    "\"why’s\": \"why is\",\n",
    "\"why’ve\": \"why have\",\n",
    "\"will’ve\": \"will have\",\n",
    "\"won’t\": \"will not\",\n",
    "\"won’t’ve\": \"will not have\",\n",
    "\"would’ve\": \"would have\",\n",
    "\"wouldn’t\": \"would not\",\n",
    "\"wouldn’t’ve\": \"would not have\",\n",
    "\"y’all\": \"you all\",\n",
    "\"y’all\": \"you all\",\n",
    "\"y’all’d\": \"you all would\",\n",
    "\"y’all’d’ve\": \"you all would have\",\n",
    "\"y’all’re\": \"you all are\",\n",
    "\"y’all’ve\": \"you all have\",\n",
    "\"you’d\": \"you would\",\n",
    "\"you’d’ve\": \"you would have\",\n",
    "\"you’ll\": \"you will\",\n",
    "\"you’ll’ve\": \"you will have\",\n",
    "\"you’re\": \"you are\",\n",
    "\"you’re\": \"you are\",\n",
    "\"you’ve\": \"you have\",\n",
    "}\n",
    "\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, embed):\n",
    "    A = embed([sent1])[0]\n",
    "    B = embed([sent2])[0]\n",
    "    return 1 - (np.dot(A,B)/(np.linalg.norm(A)*np.linalg.norm(B)))\n",
    "\n",
    "def build_similarity_matrix(sentences, embeds):\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 != idx2:\n",
    "                similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], embeds)\n",
    "    return similarity_matrix\n",
    "\n",
    "def normalize(li_word):\n",
    "    global normalized_freq\n",
    "    normalized_freq = []\n",
    "    for dictionary in li_word:\n",
    "        max_frequency = max(dictionary.values())\n",
    "        for word in dictionary.keys():\n",
    "            dictionary[word] = dictionary[word] / max_frequency\n",
    "        normalized_freq.append(dictionary)\n",
    "    return normalized_freq\n",
    "\n",
    "def word_frequency(article_word):\n",
    "    word_frequency = {}\n",
    "    li_word = []\n",
    "    for sentence in article_word:\n",
    "        for word in word_tokenize(sentence):\n",
    "            if word not in word_frequency.keys():\n",
    "                word_frequency[word] = 1\n",
    "            else:\n",
    "                word_frequency[word] += 1\n",
    "        li_word.append(word_frequency)\n",
    "        word_frequency = {}\n",
    "    normalize(li_word)\n",
    "    return normalized_freq\n",
    "\n",
    "def sentence_score(li):\n",
    "    global sentence_score_list\n",
    "    sentence_score = {}\n",
    "    sentence_score_list = []\n",
    "    for list_, dictionary in zip(li, normalized_freq):\n",
    "        for sent in list_:\n",
    "            for word in word_tokenize(sent):\n",
    "                if word in dictionary.keys():\n",
    "                    if sent not in sentence_score.keys():\n",
    "                        sentence_score[sent] = dictionary[word]\n",
    "                    else:\n",
    "                        sentence_score[sent] += dictionary[word]\n",
    "        sentence_score_list.append(sentence_score)\n",
    "        sentence_score = {}\n",
    "    return sentence_score_list\n",
    "\n",
    "def sent_token(article_sent):\n",
    "    sentence_list = []\n",
    "    sent_token = []\n",
    "    for sent in article_sent:\n",
    "        token = sent_tokenize(sent)\n",
    "        for sentence in token:\n",
    "            token_2 = ''.join(word for word in sentence if word not in punctuation)\n",
    "            token_2 = re.sub(' +', ' ', token_2)\n",
    "            sent_token.append(token_2)\n",
    "        sentence_list.append(sent_token)\n",
    "        sent_token = []\n",
    "    sentence_score(sentence_list)\n",
    "    return sentence_score_list\n",
    "\n",
    "\n",
    "def summary(sentence_score_OwO):\n",
    "    summary_list = []\n",
    "    for summ in sentence_score_OwO:\n",
    "        select_length = int(len(summ) * 0.25)\n",
    "        summary_ = nlargest(select_length, summ, key=summ.get)\n",
    "        summary_list.append(\".\".join(summary_))\n",
    "    return summary_list\n",
    "\n",
    "\n",
    "def make_series(art):\n",
    "    global dataframe\n",
    "    data_dict = {'content': [art]}\n",
    "    dataframe = pd.DataFrame(data_dict)['content']\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WASHINGTON  —   Congressional Republicans have a new fear when it comes to their    health care lawsuit against the Obama administration: They might win. The incoming Trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration’s authority to spend billions of dollars on health insurance subsidies for   and   Americans, handing House Republicans a big victory on    issues. But a sudden loss of the disputed subsidies could conceivably cause the health care program to implode, leaving millions of people without access to health insurance before Republicans have prepared a replacement. That could lead to chaos in the insurance market and spur a political backlash just as Republicans gain full control of the government. To stave off that outcome, Republicans could find themselves in the awkward position of appropriating huge sums to temporarily prop up the Obama health care law, angering conservative voters who have been demanding an end to the law for years. In another twist, Donald J. Trump’s administration, worried about preserving executive branch prerogatives, could choose to fight its Republican allies in the House on some central questions in the dispute. Eager to avoid an ugly political pileup, Republicans on Capitol Hill and the Trump transition team are gaming out how to handle the lawsuit, which, after the election, has been put in limbo until at least late February by the United States Court of Appeals for the District of Columbia Circuit. They are not yet ready to divulge their strategy. “Given that this pending litigation involves the Obama administration and Congress, it would be inappropriate to comment,” said Phillip J. Blando, a spokesman for the Trump transition effort. “Upon taking office, the Trump administration will evaluate this case and all related aspects of the Affordable Care Act. ” In a potentially   decision in 2015, Judge Rosemary M. Collyer ruled that House Republicans had the standing to sue the executive branch over a spending dispute and that the Obama administration had been distributing the health insurance subsidies, in violation of the Constitution, without approval from Congress. The Justice Department, confident that Judge Collyer’s decision would be reversed, quickly appealed, and the subsidies have remained in place during the appeal. In successfully seeking a temporary halt in the proceedings after Mr. Trump won, House Republicans last month told the court that they “and the  ’s transition team currently are discussing potential options for resolution of this matter, to take effect after the  ’s inauguration on Jan. 20, 2017. ” The suspension of the case, House lawyers said, will “provide the   and his future administration time to consider whether to continue prosecuting or to otherwise resolve this appeal. ” Republican leadership officials in the House acknowledge the possibility of “cascading effects” if the   payments, which have totaled an estimated $13 billion, are suddenly stopped. Insurers that receive the subsidies in exchange for paying    costs such as deductibles and   for eligible consumers could race to drop coverage since they would be losing money. Over all, the loss of the subsidies could destabilize the entire program and cause a lack of confidence that leads other insurers to seek a quick exit as well. Anticipating that the Trump administration might not be inclined to mount a vigorous fight against the House Republicans given the  ’s dim view of the health care law, a team of lawyers this month sought to intervene in the case on behalf of two participants in the health care program. In their request, the lawyers predicted that a deal between House Republicans and the new administration to dismiss or settle the case “will produce devastating consequences for the individuals who receive these reductions, as well as for the nation’s health insurance and health care systems generally. ” No matter what happens, House Republicans say, they want to prevail on two overarching concepts: the congressional power of the purse, and the right of Congress to sue the executive branch if it violates the Constitution regarding that spending power. House Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution. In the suit, which was initially championed by John A. Boehner, the House speaker at the time, and later in House committee reports, Republicans asserted that the administration, desperate for the funding, had required the Treasury Department to provide it despite widespread internal skepticism that the spending was proper. The White House said that the spending was a permanent part of the law passed in 2010, and that no annual appropriation was required  —   even though the administration initially sought one. Just as important to House Republicans, Judge Collyer found that Congress had the standing to sue the White House on this issue  —   a ruling that many legal experts said was flawed  —   and they want that precedent to be set to restore congressional leverage over the executive branch. But on spending power and standing, the Trump administration may come under pressure from advocates of presidential authority to fight the House no matter their shared views on health care, since those precedents could have broad repercussions. It is a complicated set of dynamics illustrating how a quick legal victory for the House in the Trump era might come with costs that Republicans never anticipated when they took on the Obama White House.\n"
     ]
    }
   ],
   "source": [
    "article_text = df_1['content'][0]\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(article_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank Summary: Anticipating that the Trump administration might not be inclined to mount a vigorous fight against the House Republicans given the ’s dim view of the health care law, a team of lawyers this month sought to intervene in the case on behalf of two participants in the health care program.. In the suit, which was initially championed by John A. Boehner, the House speaker at the time, and later in House committee reports, Republicans asserted that the administration, desperate for the funding, had required the Treasury Department to provide it despite widespread internal skepticism that the spending was proper.. ” In a potentially decision in 2015, Judge Rosemary M. Collyer ruled that House Republicans had the standing to sue the executive branch over a spending dispute and that the Obama administration had been distributing the health insurance subsidies, in violation of the Constitution, without approval from Congress.. Eager to avoid an ugly political pileup, Republicans on Capitol Hill and the Trump transition team are gaming out how to handle the lawsuit, which, after the election, has been put in limbo until at least late February by the United States Court of Appeals for the District of Columbia Circuit.. In their request, the lawyers predicted that a deal between House Republicans and the new administration to dismiss or settle the case “will produce devastating consequences for the individuals who receive these reductions, as well as for the nation’s health insurance and health care systems generally.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "def textrank(article_sent, window_size=2, damping_factor=0.85, max_iter=100, tol=1e-4):\n",
    "    sentences = [sent.split() for sent in article_sent]\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    for sentence in sentences:\n",
    "        for i, word in enumerate(sentence):\n",
    "            for j in range(i + 1, min(i + window_size + 1, len(sentence))):\n",
    "                if graph.has_edge(sentence[i], sentence[j]):\n",
    "                    graph[sentence[i]][sentence[j]]['weight'] += 1.0\n",
    "                else:\n",
    "                    graph.add_edge(sentence[i], sentence[j], weight=1.0)\n",
    "\n",
    "    pagerank_scores = nx.pagerank(graph, alpha=damping_factor, max_iter=max_iter, tol=tol)\n",
    "\n",
    "    ranked_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if not all(word in string.punctuation for word in sentence) and len(sentence) > 1:\n",
    "            score = sum(pagerank_scores.get(word, 0) for word in sentence)\n",
    "            ranked_sentences.append((score, ' '.join(sentence)))\n",
    "\n",
    "    return ranked_sentences\n",
    "\n",
    "def summarize_with_textrank(article_sent, num_sentences=5):\n",
    "    ranked_sentences = textrank(article_sent)\n",
    "    summary = [sentence for score, sentence in sorted(ranked_sentences, reverse=True)[:num_sentences]]\n",
    "    return '. '.join(summary)\n",
    "\n",
    "try:\n",
    "    article_text = df_1['content'][0] \n",
    "    article_sentences = sent_tokenize(article_text)\n",
    "    summary = summarize_with_textrank(article_sentences)\n",
    "    print(\"TextRank Summary:\", summary)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.31.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (5.3.0)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.16.4 (from gradio)\n",
      "  Downloading gradio_client-0.16.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (3.7.5)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (1.24.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.3-cp38-cp38-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading PyYAML-6.0.1.tar.gz (125 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.4.4-py3-none-macosx_11_0_arm64.whl.metadata (23 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from gradio) (2.2.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fsspec (from gradio-client==0.16.4->gradio)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n",
      "  Downloading websockets-11.0.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from altair<6.0,>=4.2.0->gradio) (4.22.0)\n",
      "Requirement already satisfied: toolz in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Collecting anyio (from httpx>=0.24.1->gradio)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
      "Collecting sniffio (from httpx>=0.24.1->gradio)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.18.2-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
      "  Downloading ujson-5.10.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio->httpx>=0.24.1->gradio)\n",
      "  Using cached exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading httptools-0.6.1-cp38-cp38-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (1.0.1)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading uvloop-0.19.0-cp38-cp38-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading watchfiles-0.21.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sakshamfaujdar/miniconda3/envs/azure/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-4.31.5-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.3-cp38-cp38-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (253 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp38-cp38-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.4.4-py3-none-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading ujson-5.10.0-cp38-cp38-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp38-cp38-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Downloading httptools-0.6.1-cp38-cp38-macosx_10_9_universal2.whl (151 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp38-cp38-macosx_10_9_universal2.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp38-cp38-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml, ffmpy\n",
      "  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-6.0.1-cp38-cp38-macosx_11_0_arm64.whl size=45365 sha256=96b72005ad8431e5dc4c38197956007bfb8453dfd750255da74f244653da4480\n",
      "  Stored in directory: /Users/sakshamfaujdar/Library/Caches/pip/wheels/77/54/77/68b3079bd1d88cb070513c3935d9f7e32c70ad69368375308d\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=5030dc037b571b7994a5337731bdb65c02f01d41a5f098e6f49ec8a152391662\n",
      "  Stored in directory: /Users/sakshamfaujdar/Library/Caches/pip/wheels/e1/2c/52/5e817a3b09f1081927f4c27751360f0189ae6957c99b6b132a\n",
      "Successfully built pyyaml ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, sniffio, shellingham, semantic-version, ruff, pyyaml, python-multipart, pydantic-core, orjson, httptools, h11, fsspec, filelock, exceptiongroup, dnspython, annotated-types, aiofiles, uvicorn, pydantic, huggingface-hub, httpcore, email_validator, anyio, watchfiles, typer, starlette, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.12.5\n",
      "    Uninstalling tomlkit-0.12.5:\n",
      "      Successfully uninstalled tomlkit-0.12.5\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 anyio-4.3.0 dnspython-2.6.1 email_validator-2.1.1 exceptiongroup-1.2.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 filelock-3.14.0 fsspec-2024.5.0 gradio-4.31.5 gradio-client-0.16.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.1 orjson-3.10.3 pydantic-2.7.1 pydantic-core-2.18.2 pydub-0.25.1 python-multipart-0.0.9 pyyaml-6.0.1 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install gradio \n",
    "import gradio as gr\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import networkx as nx\n",
    "\n",
    "def textrank(article_sent, window_size=2, damping_factor=0.85, max_iter=100, tol=1e-4):\n",
    "    sentences = [sent.split() for sent in article_sent]\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    for sentence in sentences:\n",
    "        for i, word in enumerate(sentence):\n",
    "            for j in range(i + 1, min(i + window_size + 1, len(sentence))):\n",
    "                if graph.has_edge(sentence[i], sentence[j]):\n",
    "                    graph[sentence[i]][sentence[j]]['weight'] += 1.0\n",
    "                else:\n",
    "                    graph.add_edge(sentence[i], sentence[j], weight=1.0)\n",
    "\n",
    "    pagerank_scores = nx.pagerank(graph, alpha=damping_factor, max_iter=max_iter, tol=tol)\n",
    "\n",
    "    ranked_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if not all(word in string.punctuation for word in sentence) and len(sentence) > 1:\n",
    "            score = sum(pagerank_scores.get(word, 0) for word in sentence)\n",
    "            ranked_sentences.append((score, ' '.join(sentence)))\n",
    "\n",
    "    return ranked_sentences\n",
    "\n",
    "def summarize_with_textrank(article_sent, num_sentences=5):\n",
    "    ranked_sentences = textrank(article_sent)\n",
    "    summary = [sentence for score, sentence in sorted(ranked_sentences, reverse=True)[:num_sentences]]\n",
    "    return '. '.join(summary)\n",
    "\n",
    "def summarize_article(article_text):\n",
    "    article_sentences = sent_tokenize(article_text)\n",
    "    summary = summarize_with_textrank(article_sentences)\n",
    "    return summary\n",
    "\n",
    "iface = gr.Interface(fn=summarize_article, \n",
    "                     inputs=\"textbox\", \n",
    "                     outputs=\"textbox\", \n",
    "                     title=\"Text Summarization with TextRank\", \n",
    "                     description=\"Enter an article and get a summary using TextRank algorithm.\")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
